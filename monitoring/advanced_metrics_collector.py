"""
PUBG ê³ ê¸‰ ë¶„ì„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
- ë­í‚¹ ë°ì´í„° ëª¨ë‹ˆí„°ë§
- ì´ìƒ íƒì§€ ì•Œë¦¼ ì²˜ë¦¬
- ì§‘ê³„ í†µê³„ ì‹œê°í™”
- ì„±ê³¼ íŠ¸ë Œë“œ ë¶„ì„
"""

import os
import json
import time
import logging
from datetime import datetime
import pytz
from kafka import KafkaConsumer
from kafka.errors import NoBrokersAvailable
from influxdb_client import InfluxDBClient, Point
from influxdb_client.client.write_api import SYNCHRONOUS
from threading import Thread
import concurrent.futures

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = pytz.timezone('Asia/Seoul')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# í™˜ê²½ ë³€ìˆ˜
KAFKA_BOOTSTRAP_SERVERS = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "kafka:29092")
INFLUXDB_URL = os.getenv("INFLUXDB_URL", "http://influxdb:8086")
INFLUXDB_TOKEN = os.getenv("INFLUXDB_TOKEN", "my-super-secret-auth-token")
INFLUXDB_ORG = os.getenv("INFLUXDB_ORG", "pubg-org")
INFLUXDB_BUCKET = os.getenv("INFLUXDB_BUCKET", "pubg-metrics")

class AdvancedMetricsCollector:
    def __init__(self):
        self.influx_client = None
        self.write_api = None
        self.consumers = {}
        self.running = True
        
    def create_influx_client(self):
        """InfluxDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        try:
            self.influx_client = InfluxDBClient(url=INFLUXDB_URL, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG)
            self.write_api = self.influx_client.write_api(write_options=SYNCHRONOUS)
            logging.info("InfluxDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ")
            return True
        except Exception as e:
            logging.error(f"InfluxDB ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def create_kafka_consumer(self, topic, group_id):
        """Kafka ì»¨ìŠˆë¨¸ ìƒì„±"""
        while self.running:
            try:
                consumer = KafkaConsumer(
                    topic,
                    bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
                    auto_offset_reset="latest",
                    enable_auto_commit=True,
                    group_id=group_id,
                    value_deserializer=lambda x: json.loads(x.decode("utf-8")),
                    consumer_timeout_ms=5000  # 5ì´ˆ íƒ€ì„ì•„ì›ƒ
                )
                logging.info(f"Kafka ì»¨ìŠˆë¨¸ ì—°ê²° ì„±ê³µ: {topic}")
                return consumer
            except NoBrokersAvailable:
                logging.warning(f"Kafka ë¸Œë¡œì»¤ ì—°ê²° ì‹¤íŒ¨ ({topic}). 5ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(5)
        return None
    
    def process_alerts(self):
        """ì´ìƒ íƒì§€ ì•Œë¦¼ ì²˜ë¦¬"""
        logging.info("ğŸš¨ ì´ìƒ íƒì§€ ì•Œë¦¼ ìˆ˜ì§‘ê¸° ì‹œì‘")
        
        consumer = self.create_kafka_consumer("pubg-alerts", "alerts-collector-group")
        if not consumer:
            return
            
        alert_count = 0
        
        try:
            for message in consumer:
                if not self.running:
                    break
                    
                alert_data = message.value
                current_time = datetime.utcnow()
                
                # ì´ìƒ íƒì§€ ì•Œë¦¼ ë©”íŠ¸ë¦­
                alert_point = Point("anomaly_alerts") \
                    .tag("player_name", alert_data.get("player_name", "unknown")) \
                    .tag("alert_type", alert_data.get("alert_type", "unknown")) \
                    .field("kills", float(alert_data.get("kills", 0))) \
                    .field("damage_dealt", float(alert_data.get("damage_dealt", 0))) \
                    .field("headshot_ratio", float(alert_data.get("headshot_ratio", 0))) \
                    .field("kill_zscore", float(alert_data.get("kill_zscore", 0))) \
                    .field("damage_zscore", float(alert_data.get("damage_zscore", 0))) \
                    .field("headshot_zscore", float(alert_data.get("headshot_zscore", 0))) \
                    .time(current_time)
                
                # ì•Œë¦¼ ì¹´ìš´í„°
                counter_point = Point("alert_counters") \
                    .tag("alert_type", alert_data.get("alert_type", "unknown")) \
                    .field("count", 1) \
                    .time(current_time)
                
                self.write_api.write(bucket=INFLUXDB_BUCKET, record=[alert_point, counter_point])
                alert_count += 1
                
                if alert_count % 10 == 0:
                    logging.info(f"ğŸš¨ ì´ìƒ íƒì§€ ì•Œë¦¼ {alert_count}ê±´ ì²˜ë¦¬ ì™„ë£Œ")
                    
        except Exception as e:
            logging.error(f"ì•Œë¦¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            consumer.close()
            logging.info(f"ì´ìƒ íƒì§€ ì•Œë¦¼ ìˆ˜ì§‘ê¸° ì¢…ë£Œ (ì´ {alert_count}ê±´ ì²˜ë¦¬)")
    
    def process_aggregates(self):
        """ì§‘ê³„ ë°ì´í„° ì²˜ë¦¬"""
        logging.info("ğŸ“Š ì§‘ê³„ ë°ì´í„° ìˆ˜ì§‘ê¸° ì‹œì‘")
        
        consumer = self.create_kafka_consumer("pubg-aggregates", "aggregates-collector-group")
        if not consumer:
            return
            
        aggregate_count = 0
        
        try:
            for message in consumer:
                if not self.running:
                    break
                    
                agg_data = message.value
                current_time = datetime.utcnow()
                
                # ì‹œê°„ëŒ€ë³„ ì§‘ê³„ ë©”íŠ¸ë¦­
                hourly_point = Point("hourly_aggregates") \
                    .tag("hour", agg_data.get("hour", "unknown")) \
                    .tag("game_mode", agg_data.get("game_mode", "unknown")) \
                    .tag("map_name", agg_data.get("map_name", "unknown")) \
                    .field("total_matches", int(agg_data.get("total_matches", 0))) \
                    .field("unique_players", int(agg_data.get("unique_players", 0))) \
                    .field("avg_kills", float(agg_data.get("avg_kills", 0))) \
                    .field("avg_damage", float(agg_data.get("avg_damage", 0))) \
                    .field("avg_survival", float(agg_data.get("avg_survival", 0))) \
                    .field("total_wins", int(agg_data.get("total_wins", 0))) \
                    .field("avg_headshot_ratio", float(agg_data.get("avg_headshot_ratio", 0))) \
                    .time(current_time)
                
                # ë§¤ì¹˜ ë°€ë„ ê³„ì‚° (ì‹œê°„ë‹¹ ë§¤ì¹˜ ìˆ˜)
                match_density_point = Point("match_density") \
                    .tag("game_mode", agg_data.get("game_mode", "unknown")) \
                    .tag("map_name", agg_data.get("map_name", "unknown")) \
                    .field("matches_per_hour", int(agg_data.get("total_matches", 0))) \
                    .field("players_per_hour", int(agg_data.get("unique_players", 0))) \
                    .time(current_time)
                
                self.write_api.write(bucket=INFLUXDB_BUCKET, record=[hourly_point, match_density_point])
                aggregate_count += 1
                
                if aggregate_count % 50 == 0:
                    logging.info(f"ğŸ“Š ì§‘ê³„ ë°ì´í„° {aggregate_count}ê±´ ì²˜ë¦¬ ì™„ë£Œ")
                    
        except Exception as e:
            logging.error(f"ì§‘ê³„ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            consumer.close()
            logging.info(f"ì§‘ê³„ ë°ì´í„° ìˆ˜ì§‘ê¸° ì¢…ë£Œ (ì´ {aggregate_count}ê±´ ì²˜ë¦¬)")
    
    def generate_system_health_metrics(self):
        """ì‹œìŠ¤í…œ ê±´ê°•ë„ ë©”íŠ¸ë¦­ ìƒì„±"""
        logging.info("ğŸ’“ ì‹œìŠ¤í…œ ê±´ê°•ë„ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
        while self.running:
            try:
                current_time = datetime.utcnow()
                
                # Kafka í† í”½ ìƒíƒœ ì²´í¬
                topics_health = Point("kafka_health") \
                    .field("pubg_matches_status", 1) \
                    .field("pubg_alerts_status", 1) \
                    .field("pubg_aggregates_status", 1) \
                    .time(current_time)
                
                # InfluxDB ì—°ê²° ìƒíƒœ
                influx_health = Point("influxdb_health") \
                    .field("connection_status", 1) \
                    .field("write_operations", 1) \
                    .time(current_time)
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” psutil ë“± ì‚¬ìš©)
                import random
                memory_usage = Point("system_resources") \
                    .field("memory_usage_percent", random.uniform(40, 80)) \
                    .field("cpu_usage_percent", random.uniform(20, 60)) \
                    .field("disk_usage_percent", random.uniform(30, 70)) \
                    .time(current_time)
                
                self.write_api.write(bucket=INFLUXDB_BUCKET, 
                                   record=[topics_health, influx_health, memory_usage])
                
                time.sleep(30)  # 30ì´ˆë§ˆë‹¤ ê±´ê°•ë„ ì²´í¬
                
            except Exception as e:
                logging.error(f"ì‹œìŠ¤í…œ ê±´ê°•ë„ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                time.sleep(30)
    
    def generate_performance_insights(self):
        """ì„±ê³¼ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        logging.info("ğŸ’¡ ì„±ê³¼ ì¸ì‚¬ì´íŠ¸ ìƒì„±ê¸° ì‹œì‘")
        
        while self.running:
            try:
                current_time = datetime.utcnow()
                
                # ê°€ìƒì˜ ì„±ê³¼ íŠ¸ë Œë“œ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬)
                import random
                
                # ì „ì²´ í”Œë ˆì´ì–´ ì„±ê³¼ íŠ¸ë Œë“œ
                performance_trend = Point("performance_trends") \
                    .field("avg_skill_level", random.uniform(1200, 1800)) \
                    .field("total_active_players", random.randint(500, 2000)) \
                    .field("new_player_ratio", random.uniform(0.05, 0.15)) \
                    .field("veteran_retention_rate", random.uniform(0.7, 0.9)) \
                    .time(current_time)
                
                # ê²Œì„ ë°¸ëŸ°ìŠ¤ ì§€í‘œ
                balance_metrics = Point("game_balance") \
                    .field("weapon_diversity_index", random.uniform(0.6, 0.9)) \
                    .field("map_preference_variance", random.uniform(0.1, 0.3)) \
                    .field("game_mode_popularity", random.uniform(0.4, 0.8)) \
                    .field("match_duration_stability", random.uniform(0.8, 0.95)) \
                    .time(current_time)
                
                # ê²½ìŸë„ ì§€í‘œ
                competition_level = Point("competition_metrics") \
                    .field("skill_gap_variance", random.uniform(200, 500)) \
                    .field("match_competitiveness", random.uniform(0.6, 0.9)) \
                    .field("comeback_possibility", random.uniform(0.2, 0.4)) \
                    .time(current_time)
                
                self.write_api.write(bucket=INFLUXDB_BUCKET, 
                                   record=[performance_trend, balance_metrics, competition_level])
                
                time.sleep(120)  # 2ë¶„ë§ˆë‹¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±
                
            except Exception as e:
                logging.error(f"ì„±ê³¼ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
                time.sleep(120)
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        logging.info("ğŸš€ PUBG ê³ ê¸‰ ë¶„ì„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì‹œì‘...")
        
        # InfluxDB ì—°ê²°
        if not self.create_influx_client():
            logging.error("InfluxDB ì—°ê²° ì‹¤íŒ¨ë¡œ ì¢…ë£Œ")
            return
        
        # ë©€í‹°ìŠ¤ë ˆë“œë¡œ ê° ìˆ˜ì§‘ê¸° ì‹¤í–‰
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            futures = [
                executor.submit(self.process_alerts),
                executor.submit(self.process_aggregates),
                executor.submit(self.generate_system_health_metrics),
                executor.submit(self.generate_performance_insights)
            ]
            
            try:
                # ëª¨ë“  ìŠ¤ë ˆë“œ ëŒ€ê¸°
                concurrent.futures.wait(futures)
            except KeyboardInterrupt:
                logging.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
                self.running = False
            except Exception as e:
                logging.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            finally:
                # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
                if self.influx_client:
                    self.influx_client.close()
                logging.info("ê³ ê¸‰ ë¶„ì„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì¢…ë£Œ")

if __name__ == "__main__":
    collector = AdvancedMetricsCollector()
    collector.run()